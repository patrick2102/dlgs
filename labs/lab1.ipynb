{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43c1a77-b308-4747-9dd3-8161415d0542",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Monte Carlo Tree Search Lab\n",
    "\n",
    "In this lab, we'll be using the game connect four, as a vehicle for learning MinMax and Monte Carlo Tree Search.\n",
    "We'll also introduce concepts, such as state, that'll stay relevant throughout the course.\n",
    "Expect to lose in connect four to the algorithm at the end of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df728ba-bb09-419c-80c6-3e42863c9322",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup\n",
    "This section you won't need to edit, but it is worth skimming throughâ€”this is where we declare the objects you'll be interacting with througout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6afed3e-4274-42f2-baf7-fd808e967e27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "from copy import deepcopy # world -> thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32942bc4-a6cf-4485-8b47-4e3618bc8660",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# world and world model\n",
    "class State:\n",
    "    def __init__(self, cols=7, rows=6, win_req=4):\n",
    "        self.board = [['.'] * cols for _ in range(rows)]\n",
    "        self.heights = [1] * cols\n",
    "        self.num_moves = 0\n",
    "        self.win_req = win_req\n",
    "\n",
    "    def get_avail_actions(self) -> List[int]:\n",
    "        return [i for i in range(len(self.board[0])) if self.heights[i] <= len(self.board)]\n",
    "  \n",
    "    def put_action(self, action, agent):\n",
    "        self.board[len(self.board) - self.heights[action]][action] = agent.name\n",
    "        self.heights[action] += 1\n",
    "        self.num_moves += 1\n",
    "\n",
    "    def is_over(self):\n",
    "        return self.num_moves >= len(self.board) * len(self.board[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        header  = \" \".join([str(i) for i in range(len(self.board[0]))])\n",
    "        line    = \"\".join([\"-\" for _ in range(len(header))])\n",
    "        board   = [[e for e in row] for row in self.board]\n",
    "        board   = '\\n'.join([' '.join(row) for row in board])\n",
    "        return  '\\n' + header + '\\n' + line + '\\n' + board + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "painful-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.', '.', '.', '.', '.', '.', '.'],\n",
       " ['.', '.', '.', '.', '.', '.', '.'],\n",
       " ['.', '.', '.', '.', '.', '.', '.'],\n",
       " ['.', '.', '.', '.', '.', '.', '.'],\n",
       " ['.', '.', '.', '.', '.', '.', '.'],\n",
       " ['.', '.', '.', '.', '.', '.', '.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = State()\n",
    "t.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ae7a75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the utility of a state\n",
    "def utility(state: 'State'):\n",
    "    board = state.board\n",
    "    n_cols = len(board[0]) - 1\n",
    "    n_rows = len(board) - 1\n",
    "    # print(\"n_cols: \", n_cols)\n",
    "    # print(\"n_rows: \", n_rows)\n",
    "\n",
    "    def diags_pos():\n",
    "        \"\"\"Get positive diagonals, going from bottom-left to top-right.\"\"\"\n",
    "        for di in ([(j, i - j) for j in range(n_cols)] for i in range(n_cols + n_rows - 1)):\n",
    "            yield [board[i][j] for i, j in di if i >= 0 and j >= 0 and i < n_cols and j < n_rows]\n",
    "\n",
    "    def diags_neg():\n",
    "        \"\"\"Get negative diagonals, going from top-left to bottom-right.\"\"\"\n",
    "        for di in ([(j, i - n_cols + j + 1) for j in range(n_cols)] for i in range(n_cols + n_rows - 1)):\n",
    "            yield [board[i][j] for i, j in di if i >= 0 and j >= 0 and i < n_cols and j < n_rows]\n",
    "\n",
    "    cols = list(map(list, list(zip(*board))))\n",
    "    rows = board\n",
    "    diags = list(diags_neg()) + list(diags_pos())\n",
    "    lines = rows + cols + diags\n",
    "    # lines = diags\n",
    "    strings = [\"\".join(s) for s in lines]\n",
    "    for string in strings:\n",
    "        # print(string)\n",
    "        if 'OOOO' in string:\n",
    "            return -1\n",
    "        if 'XXXX' in string:\n",
    "            return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c3e952",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parrent class for mcts, minmax, human, and any other idea for an agent you have\n",
    "class Agent:\n",
    "    def __init__(self, name: str):\n",
    "        self.name: str = name\n",
    "\n",
    "    def get_action(self, state: State):\n",
    "        return random.choice(state.get_avail_actions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb42b607-098c-41f5-a3dd-c5d44311c9c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# connecting states and agents\n",
    "class Game:\n",
    "    def __init__(self, agents: Tuple[Agent]):\n",
    "        self.agents = agents\n",
    "        self.state = State()\n",
    "\n",
    "    def play(self):\n",
    "        while utility(self.state) == 0 and not self.state.is_over():\n",
    "            for agent in agents:\n",
    "                if utility(self.state) == 0 and not self.state.is_over():\n",
    "                    action = agent.get_action(self.state)\n",
    "                    self.state.put_action(action, agent)\n",
    "                    print(self.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a8a5f-ca01-4c07-bf57-22d94ab91bef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 0: Discuss and Run game\n",
    "Let's discuss if the `utility` function best belongs to the state or the agent.\n",
    "Put the state, agent and game class together so that a game is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795cdddb-c33f-4310-ac20-0f5abd3409d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . O . O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . X . .\n",
      ". . O . O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . X . .\n",
      ". . O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . X . .\n",
      ". X O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . X . .\n",
      "O X O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". X . . X . .\n",
      "O X O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". X O . X . .\n",
      "O X O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . X . .\n",
      ". X O . X . .\n",
      "O X O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . O . X . .\n",
      ". X O . X . .\n",
      "O X O O O . .\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . X . .\n",
      ". . . . X . .\n",
      ". . O . X . .\n",
      ". X O . X . .\n",
      "O X O O O . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agents = (Agent('O'), Agent('X'))\n",
    "game = Game(agents)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377f998-91ca-4641-8307-e64c8be93491",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 1: Human Agent\n",
    "Make a child class of `Agent` called `Human`, with the `get_action` method overwritten to take input from you. *hint*: use `int(input())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2649620-9f2f-4f6a-8e57-9f216a3c3b62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Human(Agent):\n",
    "    def __init__(self, name):\n",
    "        super(Human, self).__init__(name)\n",
    "        \n",
    "    def get_action(self, state: State):\n",
    "        action = int(input())\n",
    "        while not (0 <= action <= 6):\n",
    "            action = int(input())\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "primary-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = (Agent('O'), Human('X'))\n",
    "game = Game(agents)\n",
    "#game.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fa6b2-e265-4cf0-8017-8369d4a15fef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 2: Gekko\n",
    "Make a child class of `Agent` called `Gekko`, with a `get_action` that is very short sighted (greedy). You can basically do whatever you want here, as long as your output a valid action. You might want to make a `utility` function for the agent, and perhaps some helper functions. Write a two line comment explaining your Gekko's heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b999e09-dde6-41db-8222-a7d63803d632",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Gekko(Agent):\n",
    "    def __init__(self, name, enemy = 'O'):\n",
    "        super(Gekko, self).__init__(name)\n",
    "        self.enemy = enemy\n",
    "        \n",
    "    def get_action(self, state: State):\n",
    "        #action = random.choice(state.get_avail_actions())\n",
    "        #print(self.utility(state))\n",
    "        action = self.utility(state)\n",
    "        # board = state.board\n",
    "        # print(board)\n",
    "        return action \n",
    "        \n",
    "    def diags_pos(self, rows, n_cols, n_rows):\n",
    "        \"\"\"Get positive diagonals, going from bottom-left to top-right.\"\"\"\n",
    "        for di in ([(j, i - j) for j in range(n_cols)] for i in range(n_cols + n_rows - 1)):\n",
    "            yield [rows[i][j] for i, j in di if i >= 0 and j >= 0 and i < n_cols and j < n_rows]\n",
    "        \n",
    "    def diags_neg(self, rows, n_cols, n_rows):\n",
    "        \"\"\"Get negative diagonals, going from top-left to bottom-right.\"\"\"\n",
    "        for di in ([(j, i - n_cols + j + 1) for j in range(n_cols)] for i in range(n_cols + n_rows - 1)):\n",
    "            yield [rows[i][j] for i, j in di if i >= 0 and j >= 0 and i < n_cols and j < n_rows]\n",
    "    \n",
    "    \"\"\"\n",
    "        Simple utility function that looks at the state of the board after each action taken by the agent and evaluates the utility of the action.\n",
    "        The heuristic itself is simple and creates a value based on how close the agent is to winning vs the opponent. If the opponent\n",
    "        is close to winning, the agent will aim to block the opponent, while if the agent is close to winning, it will prioritize those moves.\n",
    "    \"\"\"\n",
    "    \n",
    "    def utility(self, state: State):\n",
    "        actions = state.get_avail_actions()\n",
    "        n_cols = len(state.board[0]) - 1\n",
    "        n_rows = len(state.board) - 1\n",
    "        \n",
    "        move_utility = [0]*7\n",
    "        \n",
    "        for a in actions:\n",
    "            rows = state.board.copy()\n",
    "            rows[len(rows) - state.heights[a]][a] = self.name\n",
    "            cols = list(map(list, list(zip(*rows))))\n",
    "            diags = list(self.diags_neg(rows, n_cols, n_rows)) + list(self.diags_pos(rows, n_cols, n_rows))\n",
    "            \n",
    "            lines = rows + cols + diags\n",
    "            strings = [\"\".join(s) for s in lines]\n",
    "            \n",
    "            # Simple hardcoded heuristic that considers the placement of opponent and own move\n",
    "            opponent_score = 0\n",
    "            own_score = 0\n",
    "            \n",
    "            # Naive piece placement evaulation. Should ideally be more comprehensive and take more combinations into considerations.\n",
    "            for string in strings:\n",
    "                if str(['.',self.enemy,self.enemy,self.enemy]) in string or str([self.enemy,',', self.enemy,self.enemy]) in string  or str([self.enemy, self.enemy, ',',self.enemy]) in string  or str([self.enemy, self.enemy, self.enemy, ',']) in string:\n",
    "                #if '.OOO' in string:\n",
    "                    if opponent_score < 1000: \n",
    "                        opponent_score += 1000\n",
    "                    print(string)\n",
    "                    \n",
    "                #elif '..OO' in string  or '.O.O' in string  or '.OO.' in string  or 'O..O' in string  or 'O.O.' in string  or 'OO..' in string :\n",
    "                 #   if opponent_score < 5:\n",
    "                 #       opponent_score = 5\n",
    "            \n",
    "            for string in strings:\n",
    "                if str([self.name,self.name,self.name,self.name]) in string:\n",
    "                    own_score += 10000 # high score to make sure the agent priotizes this move if it's very close to winning.\n",
    "                    break\n",
    "                elif str(['.',self.name,self.name,self.name]) in string or str([self.name,',', self.name,self.name]) in string  or str([self.name, self.name, ',',self.name]) in string  or str([self.name, self.name, self.name, ',']) in string:\n",
    "                    own_score += 100\n",
    "                #elif '..XX' in string or '.X.X' in string or '.XX.' in string or 'X..X' in string or 'X.X.' in string or 'XX..' in string:\n",
    "                 #   own_score += 5\n",
    "            \n",
    "            \n",
    "            move_utility[a] = own_score - opponent_score\n",
    "            \n",
    "            rows[len(rows) - state.heights[a]][a] = '.'\n",
    "            \n",
    "        return move_utility.index(max(move_utility))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "discrete-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . . . . O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . O\n",
      "X . . . . . O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . . . . O\n",
      "X . . . . . O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . . O\n",
      "X . . . . . O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . . O\n",
      "X . . . . . O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . . O\n",
      "X . . . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . . O\n",
      "X . . . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . . O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . . O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . O O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . .\n",
      "X . . . . O O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . O\n",
      "X . . . . O O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . O\n",
      "X . . . . O O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "O . . . . . O\n",
      "X . O . . O O\n",
      "X . O . . O O\n",
      "\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . .\n",
      "X . . . . . O\n",
      "X . O . . O O\n",
      "X . O . . O O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agents = (Agent('O'), Gekko('X'))\n",
    "game = Game(agents)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5195ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## *Optional exercise: MinMax (useful to have done for exercise 3)*\n",
    "Make a MinMax agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b9b7de7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MinMax(Agent):\n",
    "    def __init__(self, name):\n",
    "        super(MinMax, self).__init__(name)\n",
    "        \n",
    "    def minmax(self, depth, state: State, player): \n",
    "        val = utility(state)\n",
    "        if depth == 0 or val == 1 or val == -1:\n",
    "            return val\n",
    "        \n",
    "        actions = state.get_avail_actions()\n",
    "        \n",
    "        for a in actions:\n",
    "            rows = state.board.copy()\n",
    "            rows[len(rows) - state.heights[a]][a] = player\n",
    "            cols = list(map(list, list(zip(*rows))))\n",
    "            diags = list(self.diags_neg(rows, n_cols, n_rows)) + list(self.diags_pos(rows, n_cols, n_rows))\n",
    "            \n",
    "            lines = rows + cols + diags\n",
    "            strings = [\"\".join(s) for s in lines]\n",
    "            \n",
    "            if player == 'X':\n",
    "                return max(minmax(depth-1, state, 'O'))\n",
    "            else:\n",
    "                return min(minmax(depth-1, state, 'X'))\n",
    "            \n",
    "            rows[len(rows) - state.heights[a]][a] = '.'\n",
    "        \n",
    "    \n",
    "    def utility(self, state: State):\n",
    "        rows = state.board.copy()\n",
    "        rows[len(rows) - state.heights[a]][a] = player\n",
    "        cols = list(map(list, list(zip(*rows))))\n",
    "        diags = list(self.diags_neg(rows, n_cols, n_rows)) + list(self.diags_pos(rows, n_cols, n_rows))\n",
    "            \n",
    "        lines = rows + cols + diags\n",
    "        strings = [\"\".join(s) for s in lines]\n",
    "        for string in strings:\n",
    "            if 'OOOO' in string:\n",
    "                return -1\n",
    "            if 'XXXX' in string:\n",
    "                return 1\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb1506-bff6-46b6-a05b-3c26a7e3ad26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 3: MCTS\n",
    "Same but for Monte Carlo Tree Search. See if you can beat it with a `Human`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee199e77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state: State, parent: 'Node' = None):\n",
    "        self.children: List['Nodes'] = [None] * 7\n",
    "        self.parent: 'Node' = parent\n",
    "        self.state: State = state\n",
    "        self.visits = 0\n",
    "        self.quality = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "royal-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class MCTS(Agent):\n",
    "    def __init__(self, name, enemy = 'O'):\n",
    "        super(MCTS, self).__init__(name)\n",
    "        self.enemy = enemy\n",
    "        self.exploration = 0.25\n",
    "        \n",
    "    def make_move(self, node, a, player):\n",
    "        rows = node.state.board\n",
    "        rows[len(rows) - node.state.heights[a]][a] = player\n",
    "        node.state.heights[a] += 1\n",
    "        node.state.num_moves += 1\n",
    "        \n",
    "        \n",
    "    def undo_move(self, node, a):\n",
    "        rows = node.state.board\n",
    "        node.state.heights[a] -= 1\n",
    "        node.state.num_moves -= 1\n",
    "        rows[len(rows) - node.state.heights[a]][a] = '.'\n",
    "        \n",
    "        \n",
    "    def mcts_search(self, state: State, n_searches):\n",
    "        root_node = Node(state)\n",
    "        max_depth = 100\n",
    "        \n",
    "        for i in range(n_searches):\n",
    "            node = self.select(root_node)\n",
    "            # print(\"node: \", node.state)\n",
    "            value = self.simulation(max_depth, node, 'O')\n",
    "            self.back_prop(node, value)\n",
    "            \n",
    "        print(root_node.quality)\n",
    "        print(root_node.visits)\n",
    "        actions = state.get_avail_actions()\n",
    "        \n",
    "        print(\"best actions:\")\n",
    "        \n",
    "        for a in actions:\n",
    "            c = root_node.children[a]\n",
    "            print(a, \": \", c.quality, \" / \",c.visits)\n",
    "            \n",
    "        best_child_index = self.best_child_index(root_node)\n",
    "        \n",
    "        #print(\"best child state:\")\n",
    "        #print(root_node.state)\n",
    "        #print(\"parent state:\")\n",
    "        #print(root_node.children[best_child_index].state)\n",
    "        \n",
    "        \n",
    "        return best_child_index\n",
    "        # return random.choice(state.get_avail_actions())\n",
    "    \n",
    "    def select(self, parent: Node):\n",
    "        actions = parent.state.get_avail_actions()\n",
    "        \n",
    "        # Expand child nodes that haven't been explored yet\n",
    "        for a in actions:\n",
    "            if parent.children[a] is None:\n",
    "                c_node = Node(parent.state, parent)\n",
    "                c_node.state = copy.deepcopy(parent.state)\n",
    "                self.make_move(c_node, a, 'X')\n",
    "                # print(c_node.state)\n",
    "                parent.children[a] = c_node\n",
    "                return c_node\n",
    "                \n",
    "        # For now, random\n",
    "        node = random.choice(parent.children)\n",
    "        # index = parent.children.index(node)\n",
    "        \n",
    "        return node\n",
    "        \n",
    "        # if not dead_end:\n",
    "       # best_child_index = self.best_child_index(parent)\n",
    "        \n",
    "        #return parent.children[best_child_index]\n",
    "        # return self.select(parent.children[best_child_index])\n",
    "        \n",
    "        # return self.best_child_index(parent)\n",
    "            \n",
    "    \n",
    "    def best_child_index(self, parent: Node, player = ''):\n",
    "        if player == '':\n",
    "            player = self.name\n",
    "        \n",
    "        c_values = [0]*7\n",
    "        for i in range(len(parent.children)):\n",
    "            c = parent.children[i]\n",
    "            if c is None:\n",
    "                c_values[i] = -1\n",
    "            else:\n",
    "                # print(i)\n",
    "                #c_values[i] = c.quality/c.visits\n",
    "                if player is self.name:\n",
    "                    c_values[i] = c.quality/c.visits\n",
    "                else:\n",
    "                    c_values[i] = (c.visits - c.quality)/c.visits\n",
    "                # c_values[i] = random.randint(0, 1000)\n",
    "                # print(c.quality)\n",
    "        # print(c_values)\n",
    "        \n",
    "        best = max(c_values)\n",
    "        if best == -1:\n",
    "            return -1\n",
    "        else:\n",
    "            return c_values.index(max(c_values))\n",
    "        \n",
    "    def simulation(self, depth, node: Node, player): \n",
    "        n_cols = len(node.state.board[0]) - 1\n",
    "        n_rows = len(node.state.board) - 1\n",
    "        actions = node.state.get_avail_actions()\n",
    "        result = self.utility(node.state)\n",
    "        \n",
    "        if len(actions) == 0:\n",
    "            #print(\"draw\")\n",
    "            #print(\"move: \", node.state)\n",
    "            return 0\n",
    "        \n",
    "        #a = random.choice(actions)\n",
    "        \n",
    "        if random.random() < self.exploration:\n",
    "            a = random.choice(actions)\n",
    "        else:\n",
    "            #a = random.choice(actions)\n",
    "            a = self.best_child_index(node)\n",
    "            if a == -1:\n",
    "                a = random.choice(actions)\n",
    "            \n",
    "        \n",
    "        \n",
    "        # a = self.best_child_index(node)\n",
    "        \n",
    "        rows = node.state.board\n",
    "        self.make_move(node, a, player)\n",
    "        # print(\"move: \", node.state)\n",
    "        \n",
    "        if result == 1:\n",
    "            #print(\"won\")\n",
    "            # print(\"move: \", node.state)\n",
    "            self.undo_move(node, a)\n",
    "\n",
    "            return 1\n",
    "        elif result == -1:\n",
    "            #print(\"lost\")\n",
    "            # print(\"move: \", node.state)\n",
    "            self.undo_move(node, a)\n",
    "\n",
    "            return 0\n",
    "            \n",
    "        \n",
    "        if player == self.name:\n",
    "            value = self.simulation(depth-1, node, self.enemy)\n",
    "            \n",
    "        else:\n",
    "            value = self.simulation(depth-1, node, self.name)\n",
    "            \n",
    "        self.undo_move(node, a)\n",
    "\n",
    "        return value\n",
    "        \n",
    "    \n",
    "    def back_prop(self, node: Node, value):\n",
    "        node.visits += 1\n",
    "        node.quality += value\n",
    "        if node.parent is not None:\n",
    "            self.back_prop(node.parent, value)\n",
    "    \n",
    "    def utility(self, state: State):\n",
    "        # print(\"utility\")\n",
    "        rows = state.board\n",
    "        n_cols = len(state.board[0]) - 1\n",
    "        n_rows = len(state.board)\n",
    "        cols = list(map(list, list(zip(*rows))))\n",
    "        #print(n_cols)\n",
    "        #print(n_rows)\n",
    "        \n",
    "        def diags_pos():\n",
    "            \"\"\"Get positive diagonals, going from bottom-left to top-right.\"\"\"\n",
    "            for di in ([(j, i - j) for j in range(n_cols)] for i in range(n_cols + n_rows - 1)):\n",
    "                yield [rows[i][j] for i, j in di if i >= 0 and j >= 0 and i < n_cols and j < n_rows]\n",
    "\n",
    "        def diags_neg():\n",
    "            \"\"\"Get negative diagonals, going from top-left to bottom-right.\"\"\"\n",
    "            for di in ([(j, i - n_cols + j + 1) for j in range(n_cols)] for i in range(n_cols + n_rows - 1)):\n",
    "                yield [rows[i][j] for i, j in di if i >= 0 and j >= 0 and i < n_cols and j < n_rows]\n",
    "        \n",
    "        diags = list(diags_neg()) + list(diags_pos())\n",
    "        #diags = list(self.diags_neg(rows, n_cols, n_rows)) + list(self.diags_pos(rows, n_cols, n_rows))\n",
    "            \n",
    "        lines = rows + cols + diags\n",
    "        # lines = diags\n",
    "        # lines = rows + cols\n",
    "        strings = [\"\".join(s) for s in lines]\n",
    "        for string in strings:\n",
    "            # print(string)\n",
    "            if self.enemy*4 in string:\n",
    "                #print(\"0000\")\n",
    "                return -1\n",
    "            if self.name*4 in string:\n",
    "                #print(\"XXXX\")\n",
    "                return 1\n",
    "        # print()\n",
    "        # print()\n",
    "        return 0\n",
    "        \n",
    "    \n",
    "    def get_action(self, state: State):\n",
    "        return self.mcts_search(state, 1000)\n",
    "        # return random.choice(state.get_avail_actions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "female-disposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n",
      "1000\n",
      "best actions:\n",
      "0 :  82  /  149\n",
      "1 :  72  /  156\n",
      "2 :  66  /  118\n",
      "3 :  97  /  144\n",
      "4 :  95  /  151\n",
      "5 :  80  /  134\n",
      "6 :  86  /  148\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      "\n",
      "4\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X O . .\n",
      "\n",
      "612\n",
      "1000\n",
      "best actions:\n",
      "0 :  75  /  132\n",
      "1 :  91  /  143\n",
      "2 :  89  /  158\n",
      "3 :  90  /  134\n",
      "4 :  99  /  155\n",
      "5 :  87  /  141\n",
      "6 :  81  /  137\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      ". . . X O . .\n",
      "\n",
      "3\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . X . . .\n",
      ". . . X O . .\n",
      "\n",
      "594\n",
      "1000\n",
      "best actions:\n",
      "0 :  94  /  156\n",
      "1 :  90  /  137\n",
      "2 :  93  /  151\n",
      "3 :  85  /  145\n",
      "4 :  81  /  124\n",
      "5 :  75  /  136\n",
      "6 :  76  /  151\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . X . . .\n",
      ". X . X O . .\n",
      "\n",
      "0\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". . . X . . .\n",
      "O X . X O . .\n",
      "\n",
      "537\n",
      "1000\n",
      "best actions:\n",
      "0 :  86  /  157\n",
      "1 :  93  /  143\n",
      "2 :  53  /  136\n",
      "3 :  85  /  152\n",
      "4 :  79  /  137\n",
      "5 :  70  /  134\n",
      "6 :  71  /  141\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . O . . .\n",
      ". X . X . . .\n",
      "O X . X O . .\n",
      "\n",
      "1\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". O . O . . .\n",
      ". X . X . . .\n",
      "O X . X O . .\n",
      "\n",
      "548\n",
      "1000\n",
      "best actions:\n",
      "0 :  94  /  154\n",
      "1 :  84  /  145\n",
      "2 :  63  /  142\n",
      "3 :  84  /  145\n",
      "4 :  96  /  144\n",
      "5 :  62  /  133\n",
      "6 :  65  /  137\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". O . O . . .\n",
      ". X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "0\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". O . O . . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "646\n",
      "1000\n",
      "best actions:\n",
      "0 :  99  /  138\n",
      "1 :  113  /  171\n",
      "2 :  77  /  127\n",
      "3 :  116  /  161\n",
      "4 :  89  /  135\n",
      "5 :  68  /  123\n",
      "6 :  84  /  145\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      ". O . O . . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "0\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      ". . . X . . .\n",
      "O O . O . . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "452\n",
      "1000\n",
      "best actions:\n",
      "0 :  104  /  157\n",
      "1 :  74  /  160\n",
      "2 :  51  /  130\n",
      "3 :  58  /  144\n",
      "4 :  48  /  143\n",
      "5 :  68  /  134\n",
      "6 :  49  /  132\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X . . X . . .\n",
      "O O . O . . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "1\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". . . . . . .\n",
      "X O . X . . .\n",
      "O O . O . . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "646\n",
      "1000\n",
      "best actions:\n",
      "0 :  91  /  151\n",
      "1 :  106  /  143\n",
      "2 :  74  /  138\n",
      "3 :  112  /  166\n",
      "4 :  86  /  131\n",
      "5 :  90  /  137\n",
      "6 :  87  /  134\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . . . . .\n",
      "X O . X . . .\n",
      "O O . O . . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "4\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . . . . .\n",
      "X O . X . . .\n",
      "O O . O O . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "700\n",
      "1000\n",
      "best actions:\n",
      "0 :  89  /  129\n",
      "1 :  97  /  144\n",
      "2 :  90  /  134\n",
      "3 :  115  /  159\n",
      "4 :  109  /  141\n",
      "5 :  96  /  139\n",
      "6 :  104  /  154\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . . . . .\n",
      "X O . X X . .\n",
      "O O . O O . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "3\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . O . . .\n",
      "X O . X X . .\n",
      "O O . O O . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "698\n",
      "1000\n",
      "best actions:\n",
      "0 :  98  /  145\n",
      "1 :  99  /  151\n",
      "2 :  74  /  125\n",
      "3 :  123  /  164\n",
      "4 :  109  /  135\n",
      "5 :  106  /  137\n",
      "6 :  89  /  143\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . O X . .\n",
      "X O . X X . .\n",
      "O O . O O . .\n",
      "O X . X X . .\n",
      "O X . X O . .\n",
      "\n",
      "5\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . O X . .\n",
      "X O . X X . .\n",
      "O O . O O . .\n",
      "O X . X X . .\n",
      "O X . X O O .\n",
      "\n",
      "782\n",
      "1000\n",
      "best actions:\n",
      "0 :  116  /  141\n",
      "1 :  97  /  134\n",
      "2 :  110  /  154\n",
      "3 :  117  /  141\n",
      "4 :  111  /  148\n",
      "5 :  128  /  145\n",
      "6 :  103  /  137\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . O X . .\n",
      "X O . X X . .\n",
      "O O . O O . .\n",
      "O X . X X X .\n",
      "O X . X O O .\n",
      "\n",
      "5\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . O X . .\n",
      "X O . X X . .\n",
      "O O . O O O .\n",
      "O X . X X X .\n",
      "O X . X O O .\n",
      "\n",
      "823\n",
      "1000\n",
      "best actions:\n",
      "0 :  116  /  141\n",
      "1 :  129  /  161\n",
      "2 :  107  /  135\n",
      "3 :  106  /  130\n",
      "4 :  107  /  129\n",
      "5 :  136  /  149\n",
      "6 :  122  /  155\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". . . . . . .\n",
      ". X . O X . .\n",
      "X O . X X X .\n",
      "O O . O O O .\n",
      "O X . X X X .\n",
      "O X . X O O .\n",
      "\n",
      "1\n",
      "\n",
      "0 1 2 3 4 5 6\n",
      "-------------\n",
      ". O . . . . .\n",
      ". X . O X . .\n",
      "X O . X X X .\n",
      "O O . O O O .\n",
      "O X . X X X .\n",
      "O X . X O O .\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-ac6bb9158b66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#agents = (Human('X'), Human('O'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-e91c698f1a47>\u001b[0m in \u001b[0;36mplay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_over\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-89-5ce9d09488ad>\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mState\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmcts_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;31m# return random.choice(state.get_avail_actions())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-89-5ce9d09488ad>\u001b[0m in \u001b[0;36mmcts_search\u001b[1;34m(self, state, n_searches)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m# print(\"node: \", node.state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-89-5ce9d09488ad>\u001b[0m in \u001b[0;36msimulation\u001b[1;34m(self, depth, node, player)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mn_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mn_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_avail_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state'"
     ]
    }
   ],
   "source": [
    "m = MCTS('X', 'O')\n",
    "#agents = (m, Gekko('O'))\n",
    "agents = (m, Gekko('O'))\n",
    "#agents = (m, Gekko('O'))\n",
    "#agents = (m, Human('O'))\n",
    "#agents = (Human('X'), Human('O'))\n",
    "game = Game(agents)\n",
    "game.play()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0037a71-a406-4c89-bf88-4b22eb53a135",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# *Optional exercise: Dynamic Programming*\n",
    "Then use dynamic programming to make your AI more efficient. You can use the class below (or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b6690",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TranspositionTable:\n",
    "    def __init__(self, size=1_000_000):\n",
    "        self.size = size\n",
    "        self.vals = [None] * size\n",
    "\n",
    "    def board_str(self, state: State):\n",
    "        return ''.join([''.join(c) for c in state.board])\n",
    "\n",
    "    def put(self, state: State, utility: float):\n",
    "        bstr = self.board_str(state)\n",
    "        idx = hash(bstr) % self.size\n",
    "        self.vals[idx] = (bstr, utility)\n",
    "\n",
    "    def get(self, state: State):\n",
    "        bstr = self.board_str(state)\n",
    "        idx = hash(bstr) % self.size\n",
    "        stored = self.vals[idx]\n",
    "        if stored is None:\n",
    "            return None\n",
    "        if stored[0] == bstr:\n",
    "            return stored[1]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8628c0c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
